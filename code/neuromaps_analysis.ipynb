{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from neuromaps.images import load_data, load_gifti, annot_to_gifti, relabel_gifti, construct_shape_gii\n",
    "from neuromaps.datasets import fetch_annotation\n",
    "from neuromaps.resampling import resample_images\n",
    "from neuromaps.nulls import alexander_bloch, burt2020\n",
    "from neuromaps.parcellate import Parcellater\n",
    "from scipy.stats import pearsonr\n",
    "from neuromaps import transforms \n",
    "from neuromaps.stats import compare_images\n",
    "from neuromaps.nulls import hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path\n",
    "base_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "def load_atlas(base_path):\n",
    "    \"\"\"\n",
    "    Load different parcellation files.\n",
    "    \"\"\"    \n",
    "    atlas= {\n",
    "        'dk_fsaverage_10k': (\n",
    "            os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-fsaverage_den-10k_hemi-L.label.gii.gz'),\n",
    "            os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-fsaverage_den-10k_hemi-R.label.gii.gz')\n",
    "    ),\n",
    "    'dk_fsaverage_164k': (\n",
    "            os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-fsaverage_den-164k_hemi-L.aparc-1.annot'),\n",
    "            os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-fsaverage_den-164k_hemi-R.aparc-1.annot')\n",
    "    ),\n",
    "    'dk_mni': os.path.join(base_path, 'parcellations', 'atlas-desikankilliany_space-MNI_res-1mm.nii.gz')\n",
    "    }\n",
    "    return (atlas) \n",
    "\n",
    "# create parcellaters \n",
    "def create_parcellaters(atlas):\n",
    "    dk_fsaverage_10k = relabel_gifti(atlas['dk_fsaverage_10k'])\n",
    "    parcellater_fs10k = Parcellater(dk_fsaverage_10k, 'fsaverage')\n",
    "    \n",
    "    dk_fsaverage_164k = annot_to_gifti(atlas['dk_fsaverage_164k'])  \n",
    "    parcellater_fs164k = Parcellater(dk_fsaverage_164k, 'fsaverage')\n",
    "\n",
    "    parcellater_mni = Parcellater(atlas['dk_mni'], 'MNI152')\n",
    "    return (parcellater_fs10k, parcellater_fs164k, parcellater_mni) \n",
    "\n",
    "    \n",
    "# load atlas \n",
    "atlas = load_atlas(base_path)\n",
    "parcellater_fs10k, parcellater_fs164k, parcellater_mni = create_parcellaters(atlas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get turku & enigma data \n",
    "\n",
    "def parcellated_Turku(base_path):\n",
    "    # get turku maps  \n",
    "    img_L = load_data(os.path.join(base_path, 'data', 'lh.sig.nii'))\n",
    "    img_R = load_data(os.path.join(base_path, 'data', 'rh.sig.nii'))\n",
    "    turku_map = (construct_shape_gii(img_L), construct_shape_gii(img_R))\n",
    "\n",
    "    turku_parc = parcellater_fs164k.fit_transform(turku_map, space='fsaverage', ignore_background_data=True)\n",
    "    \n",
    "    return turku_parc \n",
    "    \n",
    "turku_parc = parcellated_Turku(base_path)\n",
    "np.save(os.path.join(base_path, 'data' 'turku_parc.npy'), turku_parc)\n",
    "\n",
    "# download enigma\n",
    "enigma_file='ENIGMA_S32_partial_correlation_between_cortical_thickness_and_chlorpromazine_equivalents.csv' \n",
    "enigmamap = pd.read_csv(os.path.join(base_path, 'data',enigma_file))\n",
    "enigmamap.drop([68, 69], inplace=True)  # Remove the last two rows\n",
    "enigma_parc = enigmamap['partial_r'].to_numpy()\n",
    "\n",
    "\n",
    "# download the regions for MNI152, take indecies of surface rois  \n",
    "rois = pd.read_csv(os.path.join(base_path, 'parcellations' ,'atlas-desikankilliany.csv'))\n",
    "rois = rois[(rois['structure'] == 'cortex')].index.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get annotations \n",
    "annotations = list(fetch_annotation(source=['hcps1200',\n",
    "                                            'raichle',\n",
    "                                            'ding2010', \n",
    "                                            'finnema2016', \n",
    "                                            'dubois2015',\n",
    "                                            'gallezot2010',\n",
    "                                            'gallezot2017',\n",
    "                                            'hillmer2016',\n",
    "                                            'jaworska2020',\n",
    "                                            'kaller2017',\n",
    "                                            'kantonen2020',\n",
    "                                            'laurikainen2018',\n",
    "                                            'normandin2015',\n",
    "                                            'radnakrishnan2018',\n",
    "                                            'sandiego2015',\n",
    "                                            'satterthwaite2014',\n",
    "                                            'savli2012',\n",
    "                                            'satterthwaite2014',\n",
    "                                            'smith2017',\n",
    "                                            'tuominen',\n",
    "                                            'naganawa2020',\n",
    "                                            'fazio2016']).keys())\n",
    "\n",
    "annotations.extend(fetch_annotation(source=['norgaard2021', 'beliveau2017'], space='fsaverage').keys())\n",
    "annotations.extend(fetch_annotation(source='margulies2016', desc='fcgradient01', return_single=False).keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurituominen/anaconda3/lib/python3.10/site-packages/scipy/ndimage/_measurements.py:803: RuntimeWarning: invalid value encountered in divide\n",
      "  return sum / numpy.asanyarray(count).astype(numpy.float64)\n"
     ]
    }
   ],
   "source": [
    "# parcellate annotations\n",
    "\n",
    "# initialize\n",
    "parcellated = dict([])\n",
    "\n",
    "# go over each annotation and parcellate depending on the space \n",
    "for (src, desc, space, den) in annotations:\n",
    "\n",
    "    annot = fetch_annotation(source=src, desc=desc, space=space, den=den)\n",
    "    \n",
    "    if space == 'MNI152':\n",
    "        parcellater = parcellater_mni\n",
    "    elif space == 'fsaverage' and den == '164k':\n",
    "        parcellater = parcellater_fs164k\n",
    "    elif space == 'fsLR' and den == '164k':\n",
    "        space = 'fsaverage'\n",
    "        annot = transforms.fslr_to_fsaverage(annot, target_density='164k')\n",
    "        parcellater = parcellater_fs164k\n",
    "    elif space == 'fsLR' and den != '164k':\n",
    "        # unfortunately for fsLR-4k we are upsampling to fsaverage-10k to parcellate but it should be fine\n",
    "        space = 'fsaverage'\n",
    "        annot = transforms.fslr_to_fsaverage(annot, target_density='10k')\n",
    "        parcellater = parcellater_fs10k\n",
    "\n",
    "    parcellated[desc] = parcellater.fit_transform(annot, space=space, ignore_background_data=True)\n",
    "\n",
    "    # if subcortex included remove \n",
    "    if parcellated[desc].shape == (1,83):\n",
    "        parcellated[desc] = parcellated[desc][0][rois]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spins \n",
    "spins = pd.read_csv(os.path.join(base_path, 'parcellations', \n",
    "                                 'spins_hungarian_aparc+aseg_ctx.csv'), header=None)\n",
    "nspins = spins.values.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_corrs(annotations, parc):\n",
    "    \"\"\"\n",
    "    Calculate correlations & nulls between parcellated annotations & \n",
    "    parcellated antipsychotic effects on cortical thickness \n",
    "    \"\"\"\n",
    "\n",
    "    # initialize\n",
    "    nulls = dict([])\n",
    "    corrs = dict([])\n",
    "    \n",
    "    # go over annotations \n",
    "    for src, desc, space, den in annotations:\n",
    "        if space == 'MNI152':\n",
    "            parcellation=atlas['dk_mni']\n",
    "            \n",
    "        elif space == 'fsaverage' and den == '164k':\n",
    "            parcellation=atlas['dk_fsaverage_164k']\n",
    "            \n",
    "        elif space == 'fsLR' and den == '164k':\n",
    "            parcellation=atlas['dk_fsaverage_164k']\n",
    "            \n",
    "        elif space == 'fsLR' and den != '164k':\n",
    "            parcellation=atlas['dk_fsaverage_10k']\n",
    "        \n",
    "        # empirical correlation between annotations and parc\n",
    "        rho = pearsonr(parcellated[desc], parc)[0]\n",
    "        \n",
    "        # get 10k rotations \n",
    "        rotated = hungarian(data=parcellated[desc], n_perm=10000, spins=spins, parcellation=parcellation) \n",
    "        \n",
    "        # get null \n",
    "        n = np.zeros((nspins, ))\n",
    "        for i in range(nspins):\n",
    "            n[i] = pearsonr(parc, rotated[:,i])[0]    \n",
    "        \n",
    "        # get p-value\n",
    "        pspin = (1 + sum(abs(n) > abs(rho ))) / (nspins + 1)\n",
    "    \n",
    "        # store, multiply by -1 to make more intuitive, because smaller p-value/rho means bigger effect  \n",
    "        corrs[src+'_'+desc] = ( (-1 * rho, pspin ) )\n",
    "        nulls[src+'_'+desc] = n\n",
    "        \n",
    "    return(nulls, corrs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_turku, corrs_turku = calc_corrs(annotations, turku_parc)\n",
    "nulls_enigma, corrs_enigma = calc_corrs(annotations, enigma_parc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save correlations & nulls \n",
    "np.savez(os.path.join(base_path, 'data', 'corrs_turku.npz'), **corrs_turku)\n",
    "np.savez(os.path.join(base_path, 'data', 'nulls_turku.npz'), **nulls_turku)\n",
    "np.savez(os.path.join(base_path, 'data', 'nulls_enigma.npz'), **nulls_enigma)\n",
    "np.savez(os.path.join(base_path, 'data', 'corrs_enigma.npz'), **corrs_enigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
