{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "576c6aee-bec9-4253-9577-8839d3c5a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from neuromaps.images import load_data, load_gifti, annot_to_gifti, relabel_gifti, construct_shape_gii\n",
    "from neuromaps.resampling import resample_images\n",
    "from neuromaps.nulls import alexander_bloch, burt2020\n",
    "from neuromaps.parcellate import Parcellater\n",
    "from scipy.stats import pearsonr\n",
    "from neuromaps import transforms \n",
    "from neuromaps.stats import compare_images\n",
    "from neuromaps.nulls import hungarian\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dea46d88-b7e7-4b0b-bef3-72d7f05c9ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path\n",
    "path = '/Users/laurituominen/Documents/Research/Reettis/neuromaps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6f8e0d2-2e12-4281-903d-84511add5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load turku \n",
    "turku_parc = np.load(path + 'data/turku_parc.npy')\n",
    "\n",
    "# load enigma\n",
    "enigmamap = pd.read_csv(path+'data/ENIGMA_S32_partial_correlation_between_cortical_thickness_and_chlorpromazine_equivalents.csv')\n",
    "enigmamap.drop([68, 69], inplace=True)  # remove the last two rows\n",
    "enigma_parc = enigmamap['partial_r'].to_numpy()\n",
    "\n",
    "# load neurosynth\n",
    "neurosynth = pd.read_csv(path+'data/atl-desikankilliany_res-83_neurosynth.csv') \n",
    "rois = pd.read_csv(path+'parcellations/atlas-desikankilliany.csv')\n",
    "neurosynth['structure'] = rois['structure']\n",
    "neurosynth = neurosynth[neurosynth['structure'].str.match('cortex')]\n",
    "neurosynth.drop(['Unnamed: 0', 'structure'], axis=1,  inplace=True)\n",
    "\n",
    "# term that does not match\n",
    "categ = pd.read_csv(path + \"data/neurosynth_categories.csv\", header=None)\n",
    "categ = categ.iloc[:,0].to_list()\n",
    "idx = np.array([n in categ for n in neurosynth.columns], dtype=bool)\n",
    "neurosynth = neurosynth.iloc[:,idx]\n",
    "\n",
    "# load rois \n",
    "rois = pd.read_csv(path+'parcellations/atlas-desikankilliany.csv')\n",
    "\n",
    "# get spins \n",
    "spins = pd.read_csv(path + 'parcellations/spins_hungarian_aparc+aseg_ctx.csv', header=None)\n",
    "nspins = spins.values.shape[1]\n",
    "\n",
    "# get parcellation\n",
    "dk_fsaverage_164k = (path + 'parcellations/atlas-desikankilliany_space-fsaverage_den-164k_hemi-L.aparc-1.annot',\n",
    "                     path + 'parcellations/atlas-desikankilliany_space-fsaverage_den-164k_hemi-R.aparc-1.annot')\n",
    "dk_fsaverage_164k = annot_to_gifti(dk_fsaverage_164k)  # this does relabel_gift and also converts the annot file to gifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e7b9de-4a9a-4ab5-be85-7d03f56fd70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionary to save out later\n",
    "nulls_enigma = dict([])\n",
    "corrs_enigma = dict([])\n",
    "\n",
    "nulls_turku = dict([])\n",
    "corrs_turku = dict([])\n",
    "\n",
    "# go over annotations \n",
    "for column in neurosynth:\n",
    "    \n",
    "    # correlation between annotations and enigma map\n",
    "    rho_enigma = pearsonr(neurosynth[column].to_numpy(), enigma_parc)[0]\n",
    "    rho_turku = pearsonr(neurosynth[column].to_numpy(), turku_parc)[0]\n",
    "\n",
    "    # get 10k rotations \n",
    "    rotated = hungarian(data=neurosynth[column], n_perm=10000, spins=spins, parcellation=dk_fsaverage_164k) \n",
    "    \n",
    "    # get null Turku\n",
    "    n = np.zeros((nspins, ))\n",
    "    for i in range(nspins):\n",
    "        n[i] = pearsonr(turku_parc, rotated[:,i])[0]    \n",
    "    \n",
    "    # get p-value Turku\n",
    "    pspin = (1 + sum(abs(n) > abs(rho_turku ))) / (nspins + 1)\n",
    "\n",
    "    # store, multiply by -1 to make more intuitive  \n",
    "    corrs_turku[column] = ( (-1 * rho_turku, pspin ) )\n",
    "    nulls_turku[column] = n\n",
    "    \n",
    "    # get null enigma\n",
    "    n = np.zeros((nspins, ))\n",
    "    for i in range(nspins):\n",
    "        n[i] = pearsonr(enigma_parc, rotated[:,i])[0]    \n",
    "    \n",
    "    # get p-value enigma\n",
    "    pspin = (1 + sum(abs(n) > abs(rho_enigma ))) / (nspins + 1)\n",
    "\n",
    "    # store, multiply by -1 to make more intuitive\n",
    "    corrs_enigma[column] = ( (-1 * rho_enigma, pspin ) )\n",
    "    nulls_enigma[column] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b80e2d3d-571f-4c83-ab6c-a27da4438bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize, calculate means, permutate\n",
    "# code for this bit modified from here https://github.com/netneurolab/bazinet_assortativity/blob/master/main_script.py\n",
    "\n",
    "# Load information about categories\n",
    "def get_neurosynth_results(corrs): \n",
    "    \n",
    "    # initialize\n",
    "    neurosynth_results = {} \n",
    "    neurosynth_results['categories_labels'] = [\n",
    "        'action', 'learning and memory', 'other', 'emotion', 'attention',\n",
    "        'reasoning and decision making', 'executive/cognitive control',\n",
    "        'social function', 'perception', 'motivation', 'language']\n",
    "\n",
    "    # get categories for each term\n",
    "    neurosyn_categories = pd.read_csv(path + \"data/neurosynth_categories.csv\", header=None).values[:, 1].astype(int)\n",
    "    neurosynth_results['categories'] = neurosyn_categories\n",
    "    neurosynth_results['rho'] = np.array([value[0] for value in corrs.values()])\n",
    "\n",
    "    # Compute mean of each category\n",
    "    neurosynth_results['r_categories'] =  np.array([neurosynth_results['rho'][neurosyn_categories == 1+i].mean() \n",
    "                                                   for i in range(11)])\n",
    "\n",
    "    # Compute mean after permuting categories\n",
    "    neurosynth_results['r_categories_perm'] = np.zeros((11, 10000))\n",
    "    for i in range(11):\n",
    "        for j in range(10000):\n",
    "            perm = np.random.permutation(neurosyn_categories)\n",
    "            r_perm_mean = neurosynth_results['rho'][perm == i+1].mean()\n",
    "            neurosynth_results['r_categories_perm'][i, j] = r_perm_mean\n",
    "\n",
    "    # Compute p-values by comparing means and permuted means \n",
    "    neurosynth_results['r_categories_p'] = np.zeros((11))\n",
    "    for i in range(11):\n",
    "        neurosynth_results['r_categories_p'][i] = (1 + sum( abs(neurosynth_results['r_categories_perm'][i, :]) > abs(neurosynth_results['r_categories'][i])))/ 10001\n",
    "    \n",
    "    # multiple comparisons \n",
    "    _, neurosynth_results['r_categories_p_fdr'], _, _ = multipletests(\n",
    "    neurosynth_results['r_categories_p'], method='fdr_by')\n",
    "    \n",
    "    return(neurosynth_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f65d50d-24ba-4a6c-bcc7-1d67089c8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurosynth_results_turku = get_neurosynth_results(corrs_turku)\n",
    "neurosynth_results_enigma = get_neurosynth_results(corrs_enigma)\n",
    "\n",
    "with open(path + 'data/neurosynth_results_turku.pkl', 'wb') as f:\n",
    "    # dump the dictionary into the file\n",
    "    pickle.dump(neurosynth_results_turku, f)\n",
    "    \n",
    "with open(path + 'data/neurosynth_results_enigma.pkl', 'wb') as f:\n",
    "    # dump the dictionary into the file\n",
    "    pickle.dump(neurosynth_results_enigma, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "611209e2-4c4d-42e8-8808-81926e8de632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>enigma</th>\n",
       "      <th>enigma_fdr</th>\n",
       "      <th>turku</th>\n",
       "      <th>turku_fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>action</td>\n",
       "      <td>0.284272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learning and memory</td>\n",
       "      <td>0.914209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795420</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other</td>\n",
       "      <td>0.748825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.314669</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emotion</td>\n",
       "      <td>0.216178</td>\n",
       "      <td>0.897644</td>\n",
       "      <td>0.689931</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attention</td>\n",
       "      <td>0.176682</td>\n",
       "      <td>0.838450</td>\n",
       "      <td>0.862914</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reasoning and decision making</td>\n",
       "      <td>0.097290</td>\n",
       "      <td>0.538642</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.129540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>executive/cognitive control</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>0.176041</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.036537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>social function</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.086360</td>\n",
       "      <td>0.185481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>perception</td>\n",
       "      <td>0.021198</td>\n",
       "      <td>0.176041</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.016608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>motivation</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.086360</td>\n",
       "      <td>0.037996</td>\n",
       "      <td>0.315546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>language</td>\n",
       "      <td>0.044696</td>\n",
       "      <td>0.296945</td>\n",
       "      <td>0.507949</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           labels    enigma  enigma_fdr     turku  turku_fdr\n",
       "0                          action  0.284272    1.000000  0.709429   1.000000\n",
       "1             learning and memory  0.914209    1.000000  0.795420   1.000000\n",
       "2                           other  0.748825    1.000000  0.314669   1.000000\n",
       "3                         emotion  0.216178    0.897644  0.689931   1.000000\n",
       "4                       attention  0.176682    0.838450  0.862914   1.000000\n",
       "5   reasoning and decision making  0.097290    0.538642  0.011699   0.129540\n",
       "6     executive/cognitive control  0.018998    0.176041  0.002200   0.036537\n",
       "7                 social function  0.005199    0.086360  0.185481   1.000000\n",
       "8                      perception  0.021198    0.176041  0.000500   0.016608\n",
       "9                      motivation  0.002800    0.086360  0.037996   0.315546\n",
       "10                       language  0.044696    0.296945  0.507949   1.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'labels':['action', 'learning and memory', 'other', 'emotion', 'attention',\n",
    "        'reasoning and decision making', 'executive/cognitive control',\n",
    "        'social function', 'perception', 'motivation', 'language'],\n",
    "        'enigma': neurosynth_results_enigma['r_categories_p'],\n",
    "        'enigma_fdr': neurosynth_results_enigma['r_categories_p_fdr'], \n",
    "        'turku': neurosynth_results_turku['r_categories_p'],\n",
    "        'turku_fdr': neurosynth_results_turku['r_categories_p_fdr']})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "832928ed-be09-4afc-b751-5e2a31025e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top 10% of posivitive and top 10 % negative correlations\n",
    "#def topbottom(corrs, nulls):\n",
    "#    df1 = pd.DataFrame.from_dict(corrs_turku, orient=\"index\", columns=[\"rho\", \"pspin\"])\n",
    "#    df1.sort_values(by=\"rho\", inplace=True)\n",
    "#    df1 = pd.concat([df1.iloc[:12], df1.iloc[-12:]])\n",
    "#    index_list = list(df1.index.values)\n",
    "#    new_corrs = df1.T.to_dict(orient='list')\n",
    "    \n",
    "#    df2 = pd.DataFrame.from_dict(nulls)\n",
    "#    df2 = df2[index_list]\n",
    "#    new_nulls = df2.to_dict(orient='list')\n",
    "#    return(new_corrs, new_nulls)\n",
    "\n",
    "#corrs_turku_tb, nulls_turku_tb = topbottom(corrs_turku, nulls_turku)\n",
    "#corrs_enigma_tb, nulls_enigma_tb = topbottom(corrs_enigma, nulls_enigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aaa9e18c-cf92-4c31-91dc-9f0c4026b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save correlations & nulls \n",
    "#np.savez(path + 'data/corrs_turku_neurosynth.npz', **corrs_turku_tb)\n",
    "#np.savez(path + 'data/nulls_turku_neurosynth.npz', **nulls_turku_tb)\n",
    "#np.savez(path + 'data/nulls_enigma_neurosynth.npz', **nulls_enigma_tb)\n",
    "#np.savez(path + 'data/corrs_enigma_neurosynth.npz', **corrs_enigma_tb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
